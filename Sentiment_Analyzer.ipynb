{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 4: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # for regular expressions \n",
    "import nltk # for text manipulation \n",
    "from nltk.stem.porter import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tidy_tweet'] = np.vectorize(remove_pattern)(tweets['tweet'],\"@[\\w]*\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tidy_tweet'] = tweets['tidy_tweet'].str.replace('[^a-zA-Z# ]', \" \", regex=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tidy_tweet'] = tweets['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweet = tweets['tidy_tweet'].apply(lambda x: x.split()) #tokenizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i]) \n",
    "tweets['tidy_tweet'] = tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, \n",
    "                                   min_df=2, \n",
    "                                   max_features=1000, \n",
    "                                   stop_words='english') \n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(tweets['tidy_tweet'])\n",
    "vocab = tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(tfidf, tweets['label'], random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "lr_classifier = LogisticRegression()#\n",
    "classifiers.append(lr_classifier)\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "classifiers.append(lda_classifier)\n",
    "svc_classifier = SVC(probability=True)#\n",
    "classifiers.append(svc_classifier)\n",
    "kn_classifier = KNeighborsClassifier()#\n",
    "classifiers.append(kn_classifier)\n",
    "dt_classifier = DecisionTreeClassifier(max_depth = 10) #\n",
    "classifiers.append(dt_classifier)\n",
    "rf_classifier = RandomForestClassifier()#\n",
    "classifiers.append(rf_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_classifier.fit(X_train.toarray(), Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(probability=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = widgets.Text(description=\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a tweet:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e80a46e76844eb1b974c120fd9cb15b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='tweet')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Please enter a tweet:')\n",
    "display(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select Algorithm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee993b81b4a4d6a8c97143976419c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(options=(('Logistic Regression', 'LR'), ('Linear Discriminant Analysis ', 'LDA'), ('Support Vector Maâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithm = widgets.Dropdown(\n",
    "    options = [('Logistic Regression', 'LR'), \n",
    "               ('Linear Discriminant Analysis ', 'LDA'), \n",
    "               ('Support Vector Machines', 'SVM'),\n",
    "               ('K-Nearest Neighbors', 'KN'),\n",
    "               ('Multinomial Naive Bayes', 'MNB'),\n",
    "               ('Decision Trees', 'DT'),\n",
    "               ('Random Forest', 'RF'),\n",
    "              ],\n",
    "    disabled = False,\n",
    ")\n",
    "\n",
    "print('Select Algorithm')\n",
    "display(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = widgets.Output()\n",
    "\n",
    "button_predict = widgets.Button(description=\"Predict\")\n",
    "\n",
    "def on_button_predict_clicked(b):\n",
    "    \n",
    "    input_data = {}\n",
    "    input_data['tweet'] = tweet.value\n",
    "    \n",
    "    user_input = pd.DataFrame(input_data, columns = ['tweet'], index=[0])\n",
    "    #print(user_input)\n",
    "    user_input['tidy_tweet'] = np.vectorize(remove_pattern)(user_input['tweet'],\"@[\\w]*\") \n",
    "    user_input['tidy_tweet'] = user_input['tidy_tweet'].str.replace('[^a-zA-Z# ]', \" \", regex=True) \n",
    "    user_input['tidy_tweet'] = user_input['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "    tokenized_tweet = user_input['tidy_tweet'].apply(lambda x: x.split()) #tokenizing \n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "    detokenized_tweet = ' '.join(tokenized_tweet[0]) \n",
    "    user_input['tidy_tweet'] = detokenized_tweet\n",
    "    vectorizer = TfidfVectorizer(max_df=0.90, \n",
    "                                   min_df=2, \n",
    "                                   max_features=1000, \n",
    "                                   stop_words='english', vocabulary=vocab) \n",
    "    tf_idf = vectorizer.fit_transform(tweets['tidy_tweet']) \n",
    "    \n",
    "    selected_algorithm = algorithm.value\n",
    "    \n",
    "    if selected_algorithm == 'LR':\n",
    "        classifier = lr_classifier\n",
    "    elif selected_algorithm == 'LDA':\n",
    "        classifier = lda_classifier\n",
    "    elif selected_algorithm == 'SVM':\n",
    "        classifier = svc_classifier        \n",
    "    elif selected_algorithm == 'KN':\n",
    "        classifier = kn_classifier\n",
    "    elif selected_algorithm == 'MNB':\n",
    "        classifier = mnb_classifier\n",
    "    elif selected_algorithm == 'DT':\n",
    "        classifier = dt_classifier\n",
    "    elif selected_algorithm == 'RF':\n",
    "        classifier = rf_classifier\n",
    "        \n",
    "    with prediction:\n",
    "        clear_output(True)\n",
    "        print(f'Selected Algorithm = {selected_algorithm}')\n",
    "        print(classifier.predict(tf_idf)[0])\n",
    "        if classifier.predict(tf_idf)[0] == 0:\n",
    "            print('Postive Tweet')\n",
    "        else:\n",
    "            print('Negative Tweet')\n",
    "        \n",
    "button_predict.on_click(on_button_predict_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333ccc2155e044e088a19efddceacaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2db9764dc5e44ce8b76de17a0ea14a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(button_predict)\n",
    "display(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
