{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application 4: Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # for regular expressions \n",
    "import nltk # for text manipulation \n",
    "from nltk.stem.porter import * \n",
    "from wordcloud import WordCloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...\n",
       "6   7      0   @user camping tomorrow @user @user @user @use...\n",
       "7   8      0  the next school year is the year for exams.ð...\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['label'] == 0].head(10) #non racist/sexist tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>retweet if you agree!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>@user @user lumpy says i am a . prove it lumpy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>it's unbelievable that in the 21st century we'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>@user lets fight against  #love #peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>ð©the white establishment can't have blk fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>@user hey, white people: you can call people '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>how the #altright uses  &amp;amp; insecurity to lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>@user i'm not interested in a #linguistics tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label                                              tweet\n",
       "13    14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14    15      1  no comment!  in #australia   #opkillingbay #se...\n",
       "17    18      1                             retweet if you agree! \n",
       "23    24      1    @user @user lumpy says i am a . prove it lumpy.\n",
       "34    35      1  it's unbelievable that in the 21st century we'...\n",
       "56    57      1            @user lets fight against  #love #peace \n",
       "68    69      1  ð©the white establishment can't have blk fol...\n",
       "77    78      1  @user hey, white people: you can call people '...\n",
       "82    83      1  how the #altright uses  &amp; insecurity to lu...\n",
       "111  112      1  @user i'm not interested in a #linguistics tha..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[tweets['label'] == 1].head(10) #racist/sexist tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_tweets = tweets['tweet'].str.len() \n",
    "plt.hist(length_tweets, bins=20, label=\"tweets\") \n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "    return input_txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Twitter Handles (@user)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can't use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camping tomorrow        dannyâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcome here !  i'm   it's so #gr8 !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7   8      0  the next school year is the year for exams.ð...   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can't use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide: society now    #motivation  \n",
       "5  [2/2] huge fan fare and big talking before the...  \n",
       "6                   camping tomorrow        dannyâ¦  \n",
       "7  the next school year is the year for exams.ð...  \n",
       "8  we won!!! love the land!!! #allin #cavs #champ...  \n",
       "9              welcome here !  i'm   it's so #gr8 !   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tidy_tweet'] = np.vectorize(remove_pattern)(tweets['tweet'],\"@[\\w]*\") \n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Punctuations, Numbers, and Special Characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when a father is dysfunctional and is so sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for #lyft credit i can t use cause th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camping tomorrow        danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>the next school year is the year for exams    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>we won    love the land    #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcome here    i m   it s so #gr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7   8      0  the next school year is the year for exams.ð...   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0    when a father is dysfunctional and is so sel...  \n",
       "1    thanks for #lyft credit i can t use cause th...  \n",
       "2                                bihday your majesty  \n",
       "3  #model   i love u take with u all the time in ...  \n",
       "4             factsguide  society now    #motivation  \n",
       "5        huge fan fare and big talking before the...  \n",
       "6                   camping tomorrow        danny     \n",
       "7  the next school year is the year for exams    ...  \n",
       "8  we won    love the land    #allin #cavs #champ...  \n",
       "9              welcome here    i m   it s so #gr      "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tidy_tweet'] = tweets['tidy_tweet'].str.replace('[^a-zA-Z# ]', \" \", regex=True) \n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Short Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tidy_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when father dysfunctional selfish drags kids i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks #lyft credit cause they offer wheelchai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "      <td>huge fare talking before they leave chaos disp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "      <td>camping tomorrow danny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "      <td>next school year year exams think about that #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "      <td>love land #allin #cavs #champions #cleveland #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "      <td>welcome here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "3   4      0  #model   i love u take with u all the time in ...   \n",
       "4   5      0             factsguide: society now    #motivation   \n",
       "5   6      0  [2/2] huge fan fare and big talking before the...   \n",
       "6   7      0   @user camping tomorrow @user @user @user @use...   \n",
       "7   8      0  the next school year is the year for exams.ð...   \n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...   \n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr...   \n",
       "\n",
       "                                          tidy_tweet  \n",
       "0  when father dysfunctional selfish drags kids i...  \n",
       "1  thanks #lyft credit cause they offer wheelchai...  \n",
       "2                                bihday your majesty  \n",
       "3                         #model love take with time  \n",
       "4                     factsguide society #motivation  \n",
       "5  huge fare talking before they leave chaos disp...  \n",
       "6                             camping tomorrow danny  \n",
       "7  next school year year exams think about that #...  \n",
       "8  love land #allin #cavs #champions #cleveland #...  \n",
       "9                                       welcome here  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tidy_tweet'] = tweets['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Text Normalization**\n",
    "\n",
    "Tokenize --> Normalize (using nltk’s PorterStemmer() function)\n",
    "\n",
    "Tokens are individual terms or words.\n",
    "\n",
    "Tokenization is the process of splitting a string of text into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, dysfunctional, selfish, drags, ...\n",
       "1    [thanks, #lyft, credit, cause, they, offer, wh...\n",
       "2                              [bihday, your, majesty]\n",
       "3                     [#model, love, take, with, time]\n",
       "4                   [factsguide, society, #motivation]\n",
       "5    [huge, fare, talking, before, they, leave, cha...\n",
       "6                           [camping, tomorrow, danny]\n",
       "7    [next, school, year, year, exams, think, about...\n",
       "8    [love, land, #allin, #cavs, #champions, #cleve...\n",
       "9                                      [welcome, here]\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweet = tweets['tidy_tweet'].apply(lambda x: x.split()) #tokenizing \n",
    "tokenized_tweet.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [when, father, dysfunct, selfish, drag, kid, i...\n",
       "1    [thank, #lyft, credit, caus, they, offer, whee...\n",
       "2                              [bihday, your, majesti]\n",
       "3                     [#model, love, take, with, time]\n",
       "4                         [factsguid, societi, #motiv]\n",
       "5    [huge, fare, talk, befor, they, leav, chao, di...\n",
       "6                              [camp, tomorrow, danni]\n",
       "7    [next, school, year, year, exam, think, about,...\n",
       "8    [love, land, #allin, #cav, #champion, #clevela...\n",
       "9                                       [welcom, here]\n",
       "Name: tidy_tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer() \n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_tweet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join tokens back using nltk’s MosesDetokenizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detokenized_tweet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1b261bea24eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_tweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdetokenized_tweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_tweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tidy_tweet'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetokenized_tweet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtokenized_tweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detokenized_tweet' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(tokenized_tweet)):\n",
    "    detokenized_tweet[i] = ' '.join(tokenized_tweet[i]) \n",
    "tweets['tidy_tweet'] = detokenized_tweet\n",
    "tokenized_tweet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the common words used in the tweets: WordCloud**\n",
    "\n",
    "Most frequent words appear in large size and the less\n",
    "frequent words appear in smaller sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = ' '.join([text for text in tweets['tidy_tweet']]) \n",
    " \n",
    "wordcloud = WordCloud(width=800, \n",
    "                      height=500,\n",
    "                      random_state=21, \n",
    "                      max_font_size=110).generate(all_words) \n",
    "\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see most of the words are positive or neutral. Words like love, great, friend, life are the most frequent ones. It doesn’t give us any idea about the words associated with the racist/sexist tweets. Hence, we will plot separate wordclouds for both the classes (racist/sexist or not) in our tweets data.\n",
    "\n",
    "Words in non racist/sexist tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_words =' '.join([text for text in tweets['tidy_tweet'][tweets['label'] == 0]]) \n",
    "\n",
    "wordcloud = WordCloud(width=800, \n",
    "                      height=500, \n",
    "                      random_state=21,\n",
    "                      max_font_size=110).generate(normal_words) \n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(wordcloud) \n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Racist/Sexist Tweets\n",
    "negative_words = ' '.join([text for text in tweets['tidy_tweet'][tweets['label'] == 1]])\n",
    "\n",
    "wordcloud = WordCloud(width=800, \n",
    "                      height=500,\n",
    "                      random_state=21, \n",
    "                      max_font_size=110).generate(negative_words)\n",
    "\n",
    "plt.figure(figsize=(10, 7)) \n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the impact of Hashtags on tweets sentiment**\n",
    "\n",
    "Hashtags in twitter are synonymous with the ongoing trends on twitter at any particular point in time. We should try to check whether these hashtags add any value to our sentiment analysis\n",
    "task, i.e., they help in distinguishing tweets into the different sentiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to collect hashtags \n",
    "def hashtag_extract(x): \n",
    "    hashtags = [] \n",
    "    # Loop over the words in the tweet \n",
    "    for i in x: \n",
    "        ht = re.findall(r\"#(\\w+)\", i) \n",
    "        hashtags.append(ht) \n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting hashtags from non racist/sexist tweets \n",
    "HT_regular = hashtag_extract(tweets['tidy_tweet'][tweets['label'] == 0]) \n",
    "print(HT_regular[0:5])\n",
    "\n",
    "# extracting hashtags from racist/sexist tweets \n",
    "HT_negative = hashtag_extract(tweets['tidy_tweet'][tweets['label'] == 1]) \n",
    "print(HT_negative[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnesting list \n",
    "HT_regular = sum(HT_regular, []) \n",
    "print(HT_regular[0:5])\n",
    "\n",
    "HT_negative = sum(HT_negative, [])\n",
    "print(HT_negative[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-Racist/Sexist Tweets\n",
    "frequency_distribution = nltk.FreqDist(HT_regular) \n",
    "df = pd.DataFrame({'Hashtag': list(frequency_distribution.keys()), 'Count': list(frequency_distribution.values())}) \n",
    "\n",
    "# selecting top 20 most frequent hashtags \n",
    "df = df.nlargest(columns=\"Count\", n = 20) \n",
    "\n",
    "plt.figure(figsize=(16,5)) \n",
    "ax = sns.barplot(data=df, x= \"Hashtag\", y = \"Count\") \n",
    "ax.set(ylabel = 'Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these hashtags are positive and it makes sense. We expect negative terms in the plot of\n",
    "the second list.\n",
    "\n",
    "**Checking the most frequent hashtags appearing in the racist/sexist tweets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Racist/Sexist Tweets\n",
    "b = nltk.FreqDist(HT_negative) \n",
    "e = pd.DataFrame({'Hashtag': list(b.keys()),'Count': list(b.values())}) \n",
    "\n",
    "# selecting top 20 most frequent hashtags \n",
    "e = e.nlargest(columns=\"Count\", n = 20) \n",
    "plt.figure(figsize=(16,5)) \n",
    "ax = sns.barplot(data=e, x= \"Hashtag\", y = \"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, \n",
    "                                   min_df=2, \n",
    "                                   max_features=1000, \n",
    "                                   stop_words='english') \n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(tweets['tidy_tweet'])\n",
    "vocab = tfidf_vectorizer.vocabulary_\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(tfidf, tweets['label'], random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(tfidf)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "\n",
    "lr_classifier = LogisticRegression()#\n",
    "classifiers.append(lr_classifier)\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "classifiers.append(lda_classifier)\n",
    "svc_classifier = SVC(probability=True)#\n",
    "classifiers.append(svc_classifier)\n",
    "kn_classifier = KNeighborsClassifier()#\n",
    "classifiers.append(kn_classifier)\n",
    "gnb_classifier = GaussianNB() #\n",
    "classifiers.append(gnb_classifier)\n",
    "dt_classifier = DecisionTreeClassifier(max_depth = 10) #\n",
    "classifiers.append(dt_classifier)\n",
    "rf_classifier = RandomForestClassifier()#\n",
    "classifiers.append(rf_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_classifier.fit(X_train, Y_train)\n",
    "y_pred = mnb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier.fit(X_train, Y_train)\n",
    "prediction = lr_classifier.predict(X_test) \n",
    "print(metrics.accuracy_score(Y_test, prediction))\n",
    "print(metrics.precision_score(Y_test, prediction))\n",
    "print(metrics.recall_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_classifier.fit(X_train.toarray(), Y_train)\n",
    "prediction = lda_classifier.predict(X_test.toarray()) \n",
    "print(metrics.accuracy_score(Y_test, prediction))\n",
    "print(metrics.precision_score(Y_test, prediction))\n",
    "print(metrics.recall_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier.fit(X_train, Y_train)\n",
    "prediction = svc_classifier.predict(X_test) \n",
    "print(metrics.accuracy_score(Y_test, prediction))\n",
    "print(metrics.precision_score(Y_test, prediction))\n",
    "print(metrics.recall_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_classifier.fit(X_train, Y_train)\n",
    "prediction = kn_classifier.predict(X_test) \n",
    "print(metrics.accuracy_score(Y_test, prediction))\n",
    "print(metrics.precision_score(Y_test, prediction))\n",
    "print(metrics.recall_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier.fit(X_train, Y_train)\n",
    "prediction = dt_classifier.predict(X_test) \n",
    "print(metrics.accuracy_score(Y_test, prediction))\n",
    "print(metrics.precision_score(Y_test, prediction))\n",
    "print(metrics.recall_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = plot_tree(dt_classifier, \n",
    "              filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"decision_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(X_train, Y_train)\n",
    "prediction = rf_classifier.predict(X_test) \n",
    "print(metrics.accuracy_score(Y_test, prediction))\n",
    "print(metrics.precision_score(Y_test, prediction))\n",
    "print(metrics.recall_score(Y_test, prediction))\n",
    "\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "plot_tree(rf_classifier.estimators_[0], \n",
    "                  max_depth = 5,\n",
    "                  rounded = True, \n",
    "                  precision = 2,\n",
    "                  filled = True,\n",
    "                  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,10))\n",
    "plot_tree(rf_classifier.estimators_[1], \n",
    "                  max_depth = 5,\n",
    "                  rounded = True, \n",
    "                  precision = 2,\n",
    "                  filled = True,\n",
    "                  )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = widgets.Text(description=\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = widgets.Dropdown(\n",
    "    options = [('Logistic Regression', 'LR'), \n",
    "               ('Linear Discriminant Analysis ', 'LDA'), \n",
    "               ('Support Vector Machines', 'SVM'),\n",
    "               ('K-Nearest Neighbors', 'KN'),\n",
    "               ('Multinomial Naive Bayes', 'MNB'),\n",
    "               ('Decision Trees', 'DT'),\n",
    "               ('Random Forest', 'RF'),\n",
    "              ],\n",
    "    disabled = False,\n",
    ")\n",
    "\n",
    "print('Select Algorithm')\n",
    "display(algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = widgets.Output()\n",
    "\n",
    "button_predict = widgets.Button(description=\"Predict\")\n",
    "\n",
    "def on_button_predict_clicked(b):\n",
    "    \n",
    "    input_data = {}\n",
    "    input_data['tweet'] = tweet.value\n",
    "    \n",
    "    user_input = pd.DataFrame(input_data, columns = ['tweet'], index=[0])\n",
    "    #print(user_input)\n",
    "    user_input['tidy_tweet'] = np.vectorize(remove_pattern)(user_input['tweet'],\"@[\\w]*\") \n",
    "    user_input['tidy_tweet'] = user_input['tidy_tweet'].str.replace('[^a-zA-Z# ]', \" \", regex=True) \n",
    "    user_input['tidy_tweet'] = user_input['tidy_tweet'].apply(lambda x:' '.join([w for w in x.split() if len(w)>3]))\n",
    "    tokenized_tweet = user_input['tidy_tweet'].apply(lambda x: x.split()) #tokenizing \n",
    "    tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "    detokenized_tweet = ' '.join(tokenized_tweet[0]) \n",
    "    user_input['tidy_tweet'] = detokenized_tweet\n",
    "    vectorizer = TfidfVectorizer(max_df=0.90, \n",
    "                                   min_df=2, \n",
    "                                   max_features=1000, \n",
    "                                   stop_words='english', vocabulary=vocab) \n",
    "    tf_idf = vectorizer.fit_transform(tweets['tidy_tweet']) \n",
    "    \n",
    "    selected_algorithm = algorithm.value\n",
    "    \n",
    "    if selected_algorithm == 'LR':\n",
    "        classifier = lr_classifier\n",
    "    elif selected_algorithm == 'LDA':\n",
    "        classifier = lda_classifier\n",
    "    elif selected_algorithm == 'SVM':\n",
    "        classifier = svc_classifier        \n",
    "    elif selected_algorithm == 'KN':\n",
    "        classifier = kn_classifier\n",
    "    elif selected_algorithm == 'MNB':\n",
    "        classifier = mnb_classifier\n",
    "    elif selected_algorithm == 'DT':\n",
    "        classifier = dt_classifier\n",
    "    elif selected_algorithm == 'RF':\n",
    "        classifier = rf_classifier\n",
    "        \n",
    "    with prediction:\n",
    "        clear_output(True)\n",
    "        print(f'Selected Algorithm = {selected_algorithm}')\n",
    "        print(classifier.predict(tf_idf)[0])\n",
    "        \n",
    "button_predict.on_click(on_button_predict_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(button_predict)\n",
    "display(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
